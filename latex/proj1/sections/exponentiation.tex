\section{Exponentiation}

\begin{figure}
  \begin{center}
    \includesvg[inkscapelatex=false, width=0.7\textwidth, keepaspectratio]{images/naive.svg}
  \end{center}
  \caption{Naive exponentiation of $a^n \mod{p}$ where $n=p$.}\label{fig:naive-plot}
\end{figure}

\begin{figure}
  \begin{center}
    \includesvg[inkscapelatex=false, width=0.7\textwidth, keepaspectratio]{images/square.svg}
  \end{center}
  \caption{Exponentiation using square-and-multiply of $a^n \mod{p}$ where $n=p$, plotted with a logarithmic $x$-axis.}\label{fig:square}
\end{figure}

\begin{figure}
  \begin{center}
    \includesvg[inkscapelatex=false, width=0.7\textwidth, keepaspectratio]{images/naive-square.svg}
  \end{center}
  \caption{Comparison of naive exponentiation and square-and-multiply of $a^n \mod{p}$, where $n=p$.}\label{fig:square-naive}
\end{figure}


We will now consider the problem 

\begin{equation}
  a^n \mod{p}
  \label{eq:exp}
\end{equation}

for $p$ a prime. Naively you can implement this very simply as

\begin{algorithm}
  \caption{Naive exponentiation}
  \label{alg:naive_exp}
  \textbf{Input:} $a \in \M{Z}_p, \quad n \in \M{Z}, \quad p \in \M{Z}$. \\
  \textbf{Output:} $a^n \mod{p}$
  \begin{algorithmic}[1]
    \State $b \gets 1$
    \For{$i$ from $1$ to $n$}
      \State $b \gets b \cdot a \mod{p}$
    \EndFor \\
    \Return $b$
  \end{algorithmic}
\end{algorithm}

However, we notice that this is very many multiplications for large $b$.
So we introduce another algorithm

\begin{algorithm}
  \caption{Square-and-Multiply exponentiation}
  \label{alg:square-and-multiply}
  \textbf{Input:} $a \in \M{Z}_p, \quad n \in \M{Z}, \quad p \in \M{Z}$. \\
  \textbf{Output:} $a^n \mod{p}$
  \begin{algorithmic}[1]
    \State $b \gets 1$
    \State $e \gets a \mod{p}$
    \While{$n \neq 0$}
      \If{last bit of the binary representation of $n$ is 1}
        \State $b \gets b \cdot e \mod{p}$
      \EndIf
      \State $e \gets e^2 \mod{p}$
      \State right bitwise shift of $n$
    \EndWhile \\
    \Return $b$
  \end{algorithmic}
\end{algorithm}


Now we have stated our algorithms for exponentiation. Let us do some cost analysis. \\


\subsection{Analysis of Exponentiation Algorithms}

We first consider the naive exponentiation algorithm as explained in \autoref{alg:naive_exp}.
Firstly we note that the for loop does exactly $n$ loops, and one modular multiplication per loop.
So we have a total of $\O \nbrack{n}$ modular multiplications.

Looking at the square-and-multiply algorithm as described in \autoref{alg:square-and-multiply}, we note that the while loop will loop $\lfloor \log n \rfloor$ times.
In the worst case we will then do 2 modular multiplications per loop in addition to a right bitshift.
The bitshift takes virtually no time in comparison to the modular multiplications, and so we ignore this computation.
So we do $\O \nbrack{2\log n} = \O \nbrack{ \log n }$ modular multiplications, which is significantly less than the naive algorithm.
After some experimental tests, the operation of doing modular multiplication is roughly constant for the size of the integers which are used here, so we can assume that the multiplication is constant.
We then have the following computational costs:


\begin{equation}
  \label{ref:costs}
  \begin{array}{rl}
    \text{Naive:} & \O \nbrack{n} \\
    \text{Square-and-Multiply:} & \O \nbrack{ \log n }
  \end{array}
\end{equation}

Looking at the plots, we see in \autoref{fig:naive-plot} that the naive exponentiation is in fact linear.
Likewise supporting our theoretical analysis we can note that the Square-and-Multiply approach as plotted in \autoref{fig:square} is logarithmic.
Now looking at \autoref{fig:square-naive}, we can see that there is in fact a huge difference, as expected based on our analysis.

These plots are made setting $n=p$ and choosing $a$ randomly with the same amount of digits as $p$.
Not choosing $n$ randomly is done because this would result in no very apparent pattern, as the running time of the method would be very dependent on the size of the exponent, and we would just have a plot with seemingly random points.

We may note that in \autoref{fig:square}, we can see that the plot is not as perfectly logarithmic as the naive exponentiation in \autoref{fig:naive-plot} is linear.
This is probably because we always know exactly how many times the naive exponentiation multiplies, but square-and-multiply will do $2\cdot \lfloor \log n \rfloor$ multiplications given that $n=2^k-1$.
So the amount of multiplications are also determined by the binary expansion of $n$, which will change based on what $p$ gets chosen.
This will contribute to the more chaotic graph we are seeing in \autoref{fig:square}.


